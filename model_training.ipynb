{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Satellite Imagery-Based Property Valuation\n",
        "## Multimodal Model Training\n",
        "\n",
        "This notebook implements:\n",
        "1. Baseline Model (Tabular only - XGBoost)\n",
        "2. CNN Model (Image only - ResNet18)\n",
        "3. Multimodal Fusion (Stacking meta-learner)\n",
        "4. Model Explainability (Grad-CAM)\n",
        "5. Prediction Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import pickle\n",
        "import warnings\n",
        "import cv2\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load processed data\n",
        "train_df = pd.read_csv('data/processed/train_processed.csv')\n",
        "test_df = pd.read_csv('data/processed/test_processed.csv')\n",
        "\n",
        "print(f\"Training: {train_df.shape}\")\n",
        "print(f\"Test: {test_df.shape}\")\n",
        "\n",
        "# Feature columns\n",
        "feature_cols = [col for col in train_df.columns \n",
        "               if col not in ['id', 'date', 'price', 'price_original', 'price_per_sqft']]\n",
        "print(f\"\\nFeatures: {len(feature_cols)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Baseline Model (XGBoost - Tabular Only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "X = train_df[feature_cols]\n",
        "y = train_df['price']  # Log-transformed\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost baseline\n",
        "print(\"Training XGBoost baseline...\")\n",
        "xgb_model = GradientBoostingRegressor(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "xgb_train_pred = xgb_model.predict(X_train_scaled)\n",
        "xgb_val_pred = xgb_model.predict(X_val_scaled)\n",
        "\n",
        "# Evaluate\n",
        "baseline_results = {\n",
        "    'train_rmse': np.sqrt(mean_squared_error(y_train, xgb_train_pred)),\n",
        "    'val_rmse': np.sqrt(mean_squared_error(y_val, xgb_val_pred)),\n",
        "    'val_r2': r2_score(y_val, xgb_val_pred),\n",
        "    'val_mae': mean_absolute_error(y_val, xgb_val_pred)\n",
        "}\n",
        "\n",
        "print(f\"\\nâœ“ Baseline (XGBoost) Results:\")\n",
        "print(f\"  Train RMSE: {baseline_results['train_rmse']:.4f}\")\n",
        "print(f\"  Val RMSE: {baseline_results['val_rmse']:.4f}\")\n",
        "print(f\"  Val RÂ²: {baseline_results['val_r2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CNN Model (ResNet18 - Image Only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset class for images\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, target_col='price', is_training=True):\n",
        "        self.image_dir = Path(image_dir)\n",
        "        self.target_col = target_col\n",
        "        \n",
        "        # Filter valid images\n",
        "        valid_ids = []\n",
        "        for idx, row in df.iterrows():\n",
        "            if (self.image_dir / f\"{row['id']}.png\").exists():\n",
        "                valid_ids.append(idx)\n",
        "        \n",
        "        self.df = df.loc[valid_ids].reset_index(drop=True)\n",
        "        print(f\"  Using {len(self.df)}/{len(df)} samples with images\")\n",
        "        \n",
        "        # Targets\n",
        "        if target_col and target_col in self.df.columns:\n",
        "            self.targets = self.df[target_col].values.astype(np.float32)\n",
        "        else:\n",
        "            self.targets = None\n",
        "        \n",
        "        # Transforms\n",
        "        if is_training:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        prop_id = self.df.iloc[idx]['id']\n",
        "        img = Image.open(self.image_dir / f\"{prop_id}.png\").convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        \n",
        "        if self.targets is not None:\n",
        "            return img, torch.tensor(self.targets[idx])\n",
        "        return img\n",
        "\n",
        "print(\"âœ“ Dataset class defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ResNet18 Model for regression\n",
        "class ResNet18Regressor(nn.Module):\n",
        "    def __init__(self, pretrained=True):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet18(pretrained=pretrained)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        \n",
        "        # Fine-tuning strategy: unfreeze later layers for satellite imagery\n",
        "        # Option A: Full fine-tuning (satellite images differ from ImageNet)\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = True\n",
        "        \n",
        "        # Option B: Freeze only first 2 blocks (uncomment to use)\n",
        "        # for name, child in list(self.features.named_children())[:5]:  # conv1, bn1, relu, maxpool, layer1\n",
        "        #     for param in child.parameters():\n",
        "        #         param.requires_grad = False\n",
        "        \n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.regressor(x)\n",
        "        return x\n",
        "    \n",
        "    def get_features(self, x):\n",
        "        \"\"\"Extract features before regression head\"\"\"\n",
        "        with torch.no_grad():\n",
        "            x = self.features(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "print(\"âœ“ ResNet18 model defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets and dataloaders\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Creating datasets...\")\n",
        "train_dataset = ImageDataset(train_data, 'data/images/train', is_training=True)\n",
        "val_dataset = ImageDataset(val_data, 'data/images/train', is_training=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train CNN\n",
        "cnn_model = ResNet18Regressor().to(device)\n",
        "\n",
        "# Differential learning rates: lower for pretrained backbone, higher for new head\n",
        "optimizer = optim.Adam([\n",
        "    {'params': cnn_model.features.parameters(), 'lr': 1e-5},   # Backbone: slow learning\n",
        "    {'params': cnn_model.regressor.parameters(), 'lr': 1e-3}   # Head: fast learning\n",
        "], weight_decay=1e-5)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "trainable = sum(p.numel() for p in cnn_model.parameters() if p.requires_grad)\n",
        "total = sum(p.numel() for p in cnn_model.parameters())\n",
        "print(f\"Parameters: {total:,} total, {trainable:,} trainable\")\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "best_val_loss = float('inf')\n",
        "cnn_history = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    cnn_model.train()\n",
        "    train_loss = 0\n",
        "    for images, targets in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device).unsqueeze(1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = cnn_model(images)\n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(cnn_model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_loss /= len(train_loader)\n",
        "    \n",
        "    # Validate\n",
        "    cnn_model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in val_loader:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device).unsqueeze(1)\n",
        "            outputs = cnn_model(images)\n",
        "            val_loss += criterion(outputs, targets).item()\n",
        "    \n",
        "    val_loss /= len(val_loader)\n",
        "    \n",
        "    cnn_history['train_loss'].append(train_loss)\n",
        "    cnn_history['val_loss'].append(val_loss)\n",
        "    \n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(cnn_model.state_dict(), 'models/cnn_model.pth')\n",
        "    \n",
        "    print(f\"  Train: {train_loss:.4f}, Val: {val_loss:.4f}\")\n",
        "\n",
        "print(f\"\\nâœ“ CNN training complete! Best Val Loss: {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Multimodal Fusion (Stacking Meta-Learner)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions from both models for fusion\n",
        "print(\"Generating predictions for fusion...\")\n",
        "\n",
        "# Load best CNN model\n",
        "cnn_model.load_state_dict(torch.load('models/cnn_model.pth'))\n",
        "cnn_model.eval()\n",
        "\n",
        "# Get CNN predictions for validation set\n",
        "cnn_val_preds = []\n",
        "cnn_val_targets = []\n",
        "with torch.no_grad():\n",
        "    for images, targets in tqdm(val_loader, desc='CNN predictions'):\n",
        "        images = images.to(device)\n",
        "        outputs = cnn_model(images)\n",
        "        cnn_val_preds.extend(outputs.cpu().numpy().flatten())\n",
        "        cnn_val_targets.extend(targets.numpy())\n",
        "\n",
        "cnn_val_preds = np.array(cnn_val_preds)\n",
        "cnn_val_targets = np.array(cnn_val_targets)\n",
        "\n",
        "# Get XGBoost predictions for same validation samples\n",
        "# Match validation samples by ID\n",
        "val_ids = set(val_dataset.df['id'].values)\n",
        "val_mask = train_df['id'].isin(val_ids)\n",
        "xgb_val_subset = xgb_model.predict(scaler.transform(train_df[val_mask][feature_cols]))\n",
        "\n",
        "print(f\"CNN predictions: {len(cnn_val_preds)}\")\n",
        "print(f\"XGBoost predictions: {len(xgb_val_subset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train meta-learner (Ridge regression on stacked predictions)\n",
        "print(\"Training meta-learner...\")\n",
        "\n",
        "# val_dataset.df already has all features - no merge needed!\n",
        "val_df_ordered = val_dataset.df.copy()\n",
        "val_df_ordered['cnn_pred'] = cnn_val_preds\n",
        "\n",
        "# Get XGBoost predictions directly (val_dataset.df already has feature columns)\n",
        "xgb_preds_ordered = xgb_model.predict(scaler.transform(val_df_ordered[feature_cols]))\n",
        "val_df_ordered['xgb_pred'] = xgb_preds_ordered\n",
        "\n",
        "# Stack predictions\n",
        "stacked_features = np.column_stack([val_df_ordered['xgb_pred'], val_df_ordered['cnn_pred']])\n",
        "stacked_targets = val_df_ordered['price'].values\n",
        "\n",
        "# Split for meta-learner training\n",
        "X_stack_train, X_stack_val, y_stack_train, y_stack_val = train_test_split(\n",
        "    stacked_features, stacked_targets, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train meta-learner\n",
        "meta_learner = Ridge(alpha=1.0)\n",
        "meta_learner.fit(X_stack_train, y_stack_train)\n",
        "\n",
        "# Evaluate\n",
        "meta_preds = meta_learner.predict(X_stack_val)\n",
        "\n",
        "fusion_results = {\n",
        "    'val_rmse': np.sqrt(mean_squared_error(y_stack_val, meta_preds)),\n",
        "    'val_r2': r2_score(y_stack_val, meta_preds),\n",
        "    'val_mae': mean_absolute_error(y_stack_val, meta_preds)\n",
        "}\n",
        "\n",
        "print(f\"\\nâœ“ Fusion (Stacking) Results:\")\n",
        "print(f\"  Val RMSE: {fusion_results['val_rmse']:.4f}\")\n",
        "print(f\"  Val RÂ²: {fusion_results['val_r2']:.4f}\")\n",
        "print(f\"  Weights: XGBoost={meta_learner.coef_[0]:.3f}, CNN={meta_learner.coef_[1]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "# Calculate CNN RÂ² from predictions\n",
        "cnn_r2 = r2_score(cnn_val_targets, cnn_val_preds)\n",
        "cnn_rmse = np.sqrt(mean_squared_error(cnn_val_targets, cnn_val_preds))\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['XGBoost (Tabular)', 'ResNet18 (Image)', 'Stacking (Fusion)'],\n",
        "    'Val RMSE': [baseline_results['val_rmse'], cnn_rmse, fusion_results['val_rmse']],\n",
        "    'Val RÂ²': [baseline_results['val_r2'], cnn_r2, fusion_results['val_r2']]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(comparison.to_string(index=False))\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "models = comparison['Model']\n",
        "rmse_vals = comparison['Val RMSE']\n",
        "colors = ['steelblue', 'coral', 'green']\n",
        "\n",
        "bars = ax.bar(models, rmse_vals, color=colors)\n",
        "ax.set_ylabel('Validation RMSE (log scale)')\n",
        "ax.set_title('Model Comparison', fontweight='bold')\n",
        "\n",
        "for bar, val in zip(bars, rmse_vals):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
        "            f'{val:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('models/model_comparison.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Analysis\n",
        "print(\"\\nðŸ“Š Analysis:\")\n",
        "print(\"â€¢ XGBoost captures interior features (sqft, bedrooms, grade) - strongest predictors\")\n",
        "print(\"â€¢ CNN captures visual context (lot size, neighborhood, waterfront proximity)\")\n",
        "print(\"â€¢ Fusion combines both â†’ slight improvement over tabular-only\")\n",
        "print(f\"â€¢ Improvement from fusion: {(baseline_results['val_rmse'] - fusion_results['val_rmse']) / baseline_results['val_rmse'] * 100:.1f}% RMSE reduction\")\n",
        "print(\"â€¢ This is expected: satellite images can't see interior features that dominate price\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Explainability (Grad-CAM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grad-CAM implementation\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        \n",
        "        target_layer.register_forward_hook(self.save_activation)\n",
        "        target_layer.register_full_backward_hook(self.save_gradient)\n",
        "    \n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output.detach()\n",
        "    \n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "    \n",
        "    def generate_cam(self, input_image):\n",
        "        self.model.eval()\n",
        "        output = self.model(input_image)\n",
        "        \n",
        "        self.model.zero_grad()\n",
        "        output.backward()\n",
        "        \n",
        "        weights = torch.mean(self.gradients, dim=[2, 3], keepdim=True)\n",
        "        cam = torch.sum(weights * self.activations, dim=1, keepdim=True)\n",
        "        cam = torch.relu(cam)\n",
        "        cam = cam - cam.min()\n",
        "        cam = cam / (cam.max() + 1e-8)\n",
        "        \n",
        "        return cam.squeeze().cpu().numpy()\n",
        "\n",
        "# Generate Grad-CAM for sample images\n",
        "print(\"Generating Grad-CAM visualizations...\")\n",
        "\n",
        "# Get target layer (last conv layer of ResNet18)\n",
        "# ResNet18: features[7] = layer4 (last block), [-1].conv2 = last conv\n",
        "target_layer = cnn_model.features[7][-1].conv2\n",
        "gradcam = GradCAM(cnn_model, target_layer)\n",
        "\n",
        "# Visualize on sample images\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "sample_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "for idx, (img, target) in enumerate(sample_loader):\n",
        "    if idx >= 4:\n",
        "        break\n",
        "    \n",
        "    img = img.to(device)\n",
        "    img.requires_grad = True\n",
        "    \n",
        "    cam = gradcam.generate_cam(img)\n",
        "    \n",
        "    # Original image\n",
        "    orig_img = img.squeeze().cpu().permute(1, 2, 0).numpy()\n",
        "    orig_img = (orig_img - orig_img.min()) / (orig_img.max() - orig_img.min())\n",
        "    \n",
        "    # Resize CAM\n",
        "    cam_resized = cv2.resize(cam, (224, 224))\n",
        "    \n",
        "    # Plot\n",
        "    axes[0, idx].imshow(orig_img)\n",
        "    axes[0, idx].set_title(f'Original (${np.expm1(target.item()):,.0f})')\n",
        "    axes[0, idx].axis('off')\n",
        "    \n",
        "    axes[1, idx].imshow(orig_img)\n",
        "    axes[1, idx].imshow(cam_resized, cmap='jet', alpha=0.5)\n",
        "    axes[1, idx].set_title('Grad-CAM')\n",
        "    axes[1, idx].axis('off')\n",
        "\n",
        "plt.suptitle('Model Explainability: Grad-CAM Visualizations', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('models/gradcam_samples.png', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate Test Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions on test set\n",
        "print(\"Generating test predictions...\")\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = ImageDataset(test_df, 'data/images/test', target_col=None, is_training=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Get CNN predictions\n",
        "cnn_test_preds = []\n",
        "cnn_model.eval()\n",
        "with torch.no_grad():\n",
        "    for images in tqdm(test_loader, desc='CNN predictions'):\n",
        "        images = images.to(device)\n",
        "        outputs = cnn_model(images)\n",
        "        cnn_test_preds.extend(outputs.cpu().numpy().flatten())\n",
        "\n",
        "# Get XGBoost predictions (test_dataset.df already has feature columns)\n",
        "xgb_test_preds = xgb_model.predict(scaler.transform(test_dataset.df[feature_cols]))\n",
        "\n",
        "# Combine with meta-learner\n",
        "stacked_test = np.column_stack([xgb_test_preds, cnn_test_preds])\n",
        "final_preds_log = meta_learner.predict(stacked_test)\n",
        "\n",
        "# Convert to original scale\n",
        "final_preds = np.expm1(final_preds_log)\n",
        "\n",
        "print(f\"\\nâœ“ Predictions generated!\")\n",
        "print(f\"  Mean: ${final_preds.mean():,.0f}\")\n",
        "print(f\"  Range: ${final_preds.min():,.0f} - ${final_preds.max():,.0f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create submission file\n",
        "# IMPORTANT: Replace YOUR_ENROLLNO with your actual enrollment number\n",
        "ENROLL_NO = \"YOUR_ENROLLNO\"\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_dataset.df['id'].values,\n",
        "    'predicted_price': final_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(f'{ENROLL_NO}_final.csv', index=False)\n",
        "\n",
        "print(f\"âœ“ Submission saved: {ENROLL_NO}_final.csv\")\n",
        "print(f\"\\nFirst 10 predictions:\")\n",
        "print(submission.head(10))\n",
        "\n",
        "# Save models\n",
        "pickle.dump(xgb_model, open('models/xgb_model.pkl', 'wb'))\n",
        "pickle.dump(scaler, open('models/scaler.pkl', 'wb'))\n",
        "pickle.dump(meta_learner, open('models/meta_learner.pkl', 'wb'))\n",
        "print(\"\\nâœ“ All models saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PROJECT COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nâœ“ Models trained:\")\n",
        "print(f\"  - XGBoost (Tabular): RMSE={baseline_results['val_rmse']:.4f}, RÂ²={baseline_results['val_r2']:.4f}\")\n",
        "print(f\"  - ResNet18 (Image): RMSE={cnn_rmse:.4f}, RÂ²={cnn_r2:.4f}\")\n",
        "print(f\"  - Stacking (Fusion): RMSE={fusion_results['val_rmse']:.4f}, RÂ²={fusion_results['val_r2']:.4f}\")\n",
        "print(f\"\\nâœ“ Files saved:\")\n",
        "print(f\"  - {ENROLL_NO}_final.csv (predictions)\")\n",
        "print(f\"  - models/cnn_model.pth\")\n",
        "print(f\"  - models/xgb_model.pkl\")\n",
        "print(f\"  - models/meta_learner.pkl\")\n",
        "print(f\"  - models/model_comparison.png\")\n",
        "print(f\"  - models/gradcam_samples.png\")\n",
        "print(\"\\nâœ“ Next steps:\")\n",
        "print(f\"  1. Rename {ENROLL_NO}_final.csv with your enrollment number\")\n",
        "print(f\"  2. Create report PDF: {ENROLL_NO}_report.pdf\")\n",
        "print(f\"  3. Push to GitHub\")\n",
        "print(f\"  4. Submit to portal\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
