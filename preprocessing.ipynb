{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Satellite Imagery-Based Property Valuation\n",
        "## Preprocessing and Exploratory Data Analysis\n",
        "\n",
        "This notebook covers:\n",
        "1. Data Loading and Exploration\n",
        "2. Data Cleaning\n",
        "3. Feature Engineering\n",
        "4. Exploratory Data Analysis (EDA)\n",
        "5. Geospatial Analysis\n",
        "6. Satellite Image Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"✓ Libraries imported!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Data\n",
        "train_df = pd.read_excel('data/raw/train.xlsx')\n",
        "test_df = pd.read_excel('data/raw/test.xlsx')\n",
        "\n",
        "print(f\"Training data: {train_df.shape}\")\n",
        "print(f\"Test data: {test_df.shape}\")\n",
        "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Info\n",
        "print(\"=== Data Types ===\")\n",
        "print(train_df.dtypes)\n",
        "print(\"\\n=== Missing Values ===\")\n",
        "print(train_df.isnull().sum())\n",
        "print(\"\\n=== Statistics ===\")\n",
        "train_df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def engineer_features(df):\n",
        "    \"\"\"Create new features from existing data.\"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Renovation features\n",
        "    df['is_renovated'] = (df['yr_renovated'] > 0).astype(int)\n",
        "    df['yr_renovated_filled'] = df['yr_renovated'].copy()\n",
        "    df.loc[df['yr_renovated'] == 0, 'yr_renovated_filled'] = df.loc[df['yr_renovated'] == 0, 'yr_built']\n",
        "    \n",
        "    # Age features\n",
        "    df['house_age'] = 2025 - df['yr_built']\n",
        "    df['years_since_renovation'] = 2025 - df['yr_renovated_filled']\n",
        "    \n",
        "    # Room features\n",
        "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
        "    df['bath_bed_ratio'] = df['bathrooms'] / (df['bedrooms'] + 1)\n",
        "    \n",
        "    # Space features\n",
        "    df['living_lot_ratio'] = df['sqft_living'] / df['sqft_lot']\n",
        "    df['above_living_ratio'] = df['sqft_above'] / df['sqft_living']\n",
        "    df['has_basement'] = (df['sqft_basement'] > 0).astype(int)\n",
        "    \n",
        "    # Neighborhood features\n",
        "    df['living_vs_neighbors'] = df['sqft_living'] / (df['sqft_living15'] + 1)\n",
        "    df['lot_vs_neighbors'] = df['sqft_lot'] / (df['sqft_lot15'] + 1)\n",
        "    \n",
        "    # Quality features\n",
        "    df['quality_score'] = df['grade'] * df['condition']\n",
        "    df['is_luxury'] = ((df['grade'] >= 11) | (df['waterfront'] == 1) | (df['view'] >= 3)).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "train_df = engineer_features(train_df)\n",
        "test_df = engineer_features(test_df)\n",
        "\n",
        "print(f\"✓ Feature engineering complete!\")\n",
        "print(f\"Training: {train_df.shape}\")\n",
        "print(f\"New features: {train_df.shape[1] - 21}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price Distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Original price\n",
        "axes[0].hist(train_df['price'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title('Price Distribution', fontweight='bold')\n",
        "axes[0].set_xlabel('Price ($)')\n",
        "axes[0].axvline(train_df['price'].median(), color='red', linestyle='--', \n",
        "                label=f'Median: ${train_df[\"price\"].median():,.0f}')\n",
        "axes[0].legend()\n",
        "\n",
        "# Log-transformed price\n",
        "axes[1].hist(np.log1p(train_df['price']), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
        "axes[1].set_title('Log-Transformed Price', fontweight='bold')\n",
        "axes[1].set_xlabel('Log(Price)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Price range: ${train_df['price'].min():,.0f} - ${train_df['price'].max():,.0f}\")\n",
        "print(f\"Median: ${train_df['price'].median():,.0f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Analysis\n",
        "numerical_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "numerical_cols = [col for col in numerical_cols if col not in ['id', 'date']]\n",
        "\n",
        "correlations = train_df[numerical_cols].corr()['price'].sort_values(ascending=False)\n",
        "print(\"Top 10 features correlated with price:\")\n",
        "print(correlations.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Heatmap\n",
        "top_features = correlations.head(10).index.tolist()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(train_df[top_features].corr(), annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap - Top Features', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price by Key Features\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "features = ['waterfront', 'view', 'grade', 'condition']\n",
        "for idx, feat in enumerate(features):\n",
        "    train_df.groupby(feat)['price'].mean().plot(kind='bar', ax=axes[idx], color='steelblue')\n",
        "    axes[idx].set_title(f'Average Price by {feat}', fontweight='bold')\n",
        "    axes[idx].set_ylabel('Price ($)')\n",
        "    axes[idx].tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Geospatial Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Geographic Price Distribution\n",
        "plt.figure(figsize=(12, 8))\n",
        "scatter = plt.scatter(train_df['long'], train_df['lat'], \n",
        "                      c=train_df['price'], cmap='YlOrRd', alpha=0.5, s=20)\n",
        "plt.colorbar(scatter, label='Price ($)')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Property Prices by Location', fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Waterfront premium\n",
        "waterfront_avg = train_df.groupby('waterfront')['price'].mean()\n",
        "premium = (waterfront_avg[1] / waterfront_avg[0] - 1) * 100\n",
        "print(f\"\\nWaterfront premium: {premium:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Satellite Image Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample satellite images at different price points\n",
        "images_dir = Path('data/images/train')\n",
        "images = list(images_dir.glob('*.png'))\n",
        "\n",
        "if len(images) > 0:\n",
        "    print(f\"Found {len(images)} training images\")\n",
        "    \n",
        "    # Get samples at different price points\n",
        "    price_quantiles = train_df['price'].quantile([0.1, 0.3, 0.5, 0.7, 0.9]).values\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "    for idx, q_price in enumerate(price_quantiles):\n",
        "        sample_idx = (train_df['price'] - q_price).abs().idxmin()\n",
        "        prop_id = train_df.loc[sample_idx, 'id']\n",
        "        price = train_df.loc[sample_idx, 'price']\n",
        "        \n",
        "        img_path = images_dir / f\"{prop_id}.png\"\n",
        "        if img_path.exists():\n",
        "            img = Image.open(img_path)\n",
        "            axes[idx].imshow(img)\n",
        "            axes[idx].set_title(f'${price:,.0f}', fontweight='bold')\n",
        "            axes[idx].axis('off')\n",
        "    \n",
        "    plt.suptitle('Satellite Images at Different Price Points', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images found. Run data_fetcher.py first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log-transform price for stable training\n",
        "train_df['price_original'] = train_df['price']\n",
        "train_df['price'] = np.log1p(train_df['price'])\n",
        "\n",
        "print(\"✓ Price normalized with log transform\")\n",
        "print(f\"Original: ${train_df['price_original'].min():,.0f} - ${train_df['price_original'].max():,.0f}\")\n",
        "print(f\"Log: {train_df['price'].min():.2f} - {train_df['price'].max():.2f}\")\n",
        "\n",
        "# Save processed data\n",
        "Path('data/processed').mkdir(parents=True, exist_ok=True)\n",
        "train_df.to_csv('data/processed/train_processed.csv', index=False)\n",
        "test_df.to_csv('data/processed/test_processed.csv', index=False)\n",
        "\n",
        "print(\"\\n✓ Processed data saved!\")\n",
        "print(f\"Training: data/processed/train_processed.csv ({len(train_df)} samples)\")\n",
        "print(f\"Test: data/processed/test_processed.csv ({len(test_df)} samples)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
